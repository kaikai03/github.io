Title: 最小二乘法
Date: 2013-12-16 17:59
Modified: 2013-12-16 17:59
Category: MachineLearning
Tags: ML,Linear,DataProcessing,Math
Slug: curve_fitting_2013_12_16_17_59
Authors: kai_kai03
Summary: 读书笔记--曲线拟合

## curve fitting ##

曲线拟合的最小二乘法：

由已知离散点选择与测试点误差最小的曲线。

 $$ S(x) = a_{0}\varphi_{0}(x)+a_{1}\varphi_{1}(x)+...+a_{n}\varphi_{n}(x) $$ 

若
 
 $$ (\varphi_{j},\varphi_{k})=\sum_{i=0}^{m}\omega(x_{i})\varphi_{j}(x_{i})\varphi_{k}(x_{i}) $$ 
 
 $$ (f,\varphi_{k})=\sum_{i=0}^{m}\omega(x_{i})f(x_{i})\varphi_{k}(x_{i})\equiv d_{k} $$ 

上式可写为：
 
 $$ \sum_{j=0}^{m}(\varphi_{k},\varphi_{j})a_{j}=d_{k};(k=0,1,...,n) $$ 

将该法方程改写为矩阵：
 
 $$ Ga=d $$ 

其中$ a=(a_{0},a_{1},...,a_{n})^{T},d=(d_{0},d_{1},...,d_{n})^{T} $ ，
 
 $$ \begin{aligned} &G= \end{aligned}\begin{bmatrix}&(\varphi_{0},\varphi_{0})  &(\varphi_{0},\varphi_{1})  &\cdot \cdot \cdot  &(\varphi_{0},\varphi_{n}) \\\ &(\varphi_{1},\varphi_{0})  &(\varphi_{1},\varphi_{1})  &\cdot \cdot \cdot  &(\varphi_{1},\varphi_{n}) \\\ &(\varphi_{n},\varphi_{0})  &(\varphi_{n},\varphi_{1})  &\cdot \cdot \cdot  &(\varphi_{n},\varphi_{n}) \end{bmatrix} $$


其平方误差为：

 $$ \left \| \delta  \right \|\_{2}^{2} = \sum\_{i=0}^{m}\omega(x_{i})[S(x_{i})-f(x_{i})]^2 $$ 