Title: 数据预处理技巧
Date: 2014-08-18 20:05
Modified: 2014-08-18 20:05
Category: MachineLearning
Tags: algorithm,PCA,ML
Slug: Data_Process_2014_08_18_20_05
Authors: kai_kai03
Summary: 归一与白化

参考资料：
[Data Preprocessing](http://ufldl.stanford.edu/wiki/index.php/Data_Preprocessing)

## 开头！ ##
一般来说，算法的好坏一定程度上和数据是否归一化，是否白化有关。但是在具体问题中，这些数据预处理中的参数其实还是很难准确得到的，当然了，除非你对对应的算法有非常的深刻的理解。下面就从归一化和白化两个角度来介绍下数据预处理的相关技术。

### 数据归一化 ###

数据的归一化一般包括样本尺度归一化，逐样本的均值相减，特征的标准化这3个。其中数据尺度归一化的原因是：数据中每个维度表示的意义不同，所以有可能导致该维度的变化范围不同，因此有必要将他们都归一化到一个固定的范围，一般情况下是归一化到[0 1]或者[-1 1]。这种数据归一化还有一个好处是对后续的一些默认参数（比如白化操作）不需要重新过大的更改。

逐样本的均值相减主要应用在那些具有稳定性的数据集中，也就是那些数据的每个维度间的统计性质是一样的。比如说，在自然图片中，这样就可以减小图片中亮度对数据的影响，因为我们一般很少用到亮度这个信息。不过逐样本的均值相减这只适用于一般的灰度图，在rgb等色彩图中，由于不同通道不具备统计性质相同性所以基本不会常用。

特征标准化是指对数据的每一维进行均值化和方差相等化。这在很多机器学习的算法中都非常重要，比如SVM等。

### 数据白化 ###

数据的白化是在数据归一化之后进行的。实践证明，很多deep learning算法性能提高都要依赖于数据的白化。在对数据进行白化前要求先对数据进行特征零均值化，不过一般只要 我们做了特征标准化，那么这个条件必须就满足了。在数据白化过程中，最主要的还是参数epsilon的选择，因为这个参数的选择对deep learning的结果起着至关重要的作用。

#### 简单缩放 ####
>在简单缩放中，我们的目的是通过对数据的每一个维度的值进行重新调节（这些维度可能是相互独立的），使得最终的数据向量落在 [0,1]或[ − 1,1] 的区间内（根据数据情况而定）。这对后续的处理十分重要，因为很多默认参数（如 PCA-白化中的 epsilon）都假定数据已被缩放到合理区间。

例子:在处理自然图像时，我们获得的像素值在 [0,255] 区间中，常用的处理是将这些像素值除以 255，使它们缩放到 [0,1] 中.


#### 逐样本均值消减 ####
>如果你的数据是平稳的（即数据每一个维度的统计都服从相同分布），那么你可以考虑在每个样本上减去数据的统计平均值(逐样本计算)。

例子：对于图像，这种归一化可以移除图像的平均亮度值 (intensity)。很多情况下我们对图像的照度并不感兴趣，而更多地关注其内容，这时对每个数据点移除像素的均值是有意义的。注意：虽然该方法广泛地应用于图像，但在处理彩色图像时需要格外小心，具体来说，是因为不同色彩通道中的像素并不都存在平稳特性。


#### 特征标准化 ####
>特征标准化指的是（独立地）使得数据的每一个维度具有零均值和单位方差。这是归一化中最常见的方法并被广泛地使用（例如，在使用支持向量机（SVM）时，特征标准化常被建议用作预处理的一部分）。在实际应用中，特征标准化的具体做法是：首先计算每一个维度上数据的均值（使用全体数据计算），之后在每一个维度上都减去该均值。下一步便是在数据的每一维度上除以该维度上数据的标准差。

例子:处理音频数据时，常用 Mel 倒频系数 MFCCs 来表征数据。然而MFCC特征的第一个分量（表示直流分量）数值太大，常常会掩盖其他分量。这种情况下，为了平衡各个分量的影响，通常对特征的每个分量独立地使用标准化处理。 

在基于重构的模型中（比如说常见的RBM，Sparse coding, autoencoder都属于这一类，因为他们基本上都是重构输入数据），通常是选择一个适当的epsilon值使得能够对输入数据进行低通滤波。但是何谓适当的epsilon呢？这还是很难掌握的，因为epsilon太小，则起不到过滤效果，会引入很多噪声，而且基于重构的模型又要去拟合这些噪声；epsilon太大，则又对元素数据有过大的模糊。因此一般的方法是画出变化后数据的特征值分布图，如果那些小的特征值基本都接近0，则此时的epsilon是比较合理的。如下图所示，让那个长长的尾巴接近于x轴。该图的横坐标表示的是第几个特征值，因为已经将数据集的特征值从大到小排序过。

![1.png]({filename}/article_img/Data_Process_2014_08_18_20_05/1.png)

文章中给出了个小小的实用技巧：如果数据已被缩放到合理范围(如[0,1])，可以从epsilon = 0.01或epsilon = 0.1开始调节epsilon。

基于正交化的ICA模型中，应该保持参数epsilon尽量小，因为这类模型需要对学习到的特征做正交化，以解除不同维度之间的相关性。（暂时没看懂，因为还没有时间去研究过ICA模型，等以后研究过后再来理解）。

教程中的最后是一些常见数据的预处理标准流程，其实也只是针对具体数据集而已的，所以仅供参考。

### 其他 ###

#### 大图像 ####
对于大图像，采用基于 PCA/ZCA 的白化方法是不切实际的，因为协方差矩阵太大。在这些情况下我们退而使用 1/f 白化方法

#### 自然灰度图像  ####
灰度图像具有平稳特性，我们通常在第一步对每个数据样本分别做均值消减（即减去直流分量），然后采用 PCA/ZCA 白化处理，其中的 epsilon 要足够大以达到低通滤波的效果。 


#### 彩色图像 ####
对于彩色图像，色彩通道间并不存在平稳特性。因此我们通常首先对数据进行特征缩放（使像素值位于 [0,1] 区间），然后使用足够大的 epsilon 来做 PCA/ZCA。注意在进行 PCA 变换前需要对特征进行分量均值归零化。

#### 音频 (MFCC/频谱图) ####
对于音频数据 (MFCC 和频谱图)，每一维度的取值范围（方差）不同。例如 MFCC 的第一分量是直流分量，通常其幅度远大于其他分量，尤其当特征中包含时域导数 (temporal derivatives) 时（这是音频处理中的常用方法）更是如此。因此，对这类数据的预处理通常从简单的数据标准化开始（即使得数据的每一维度均值为零、方差为 1），然后进行 PCA/ZCA 白化（使用合适的 epsilon）。 

#### MNIST 手写数字 ####
MNIST 数据集的像素值在 [0,255] 区间中。我们首先将其缩放到 [0,1] 区间。实际上，进行逐样本均值消去也有助于特征学习。注：也可选择以对 MNIST 进行 PCA/ZCA 白化，但这在实践中不常用。 