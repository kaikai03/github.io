Title: “距离”计算
Date: 2014-03-15 22:14
Modified: 2014-03-15 22:14
Category: MachineLearning
Tags: ML,clustering,algorithm,Math
Slug: distance_2014_03_15_22_14
Authors: kai_kai03
Summary: 读书随笔--k-means 的前置科技

## 各种距离 ##

### 闵可夫斯基距离 ###

$$ d_{ij}=\sqrt[\lambda]{\sum_{k=1}^{n}\left|x_{ik}-x_{jk}\right|^{\lambda}}  $$

以星型逼近,$ \lambda = 0.25 $时，几乎为一个点，$ \lambda = 1 $ 相当于曼哈顿距离，而$ \lambda = 2 $时，逼近范围是个圈，既欧式距离，$ \lambda = \infty $ 时，方型，切比雪夫距离。

### 欧式距离###

$$ d_{ij}=\sqrt[2]{\sum_{k=1}^{n}\left|x_{ik}-x_{jk}\right|^{2}} $$

以圆型逼近。

曼哈顿距离：

$$ d_{ij}=\sum_{k=1}^{n}\left|x_{ik}-x_{jk}\right| $$

以菱型逼近。

#### 问题 ####
闵氏距离，曼哈顿距离、欧氏距离和切比雪夫距离都存在明显的缺点。
举个例子：
>二维样本(身高,体重)，其中身高范围是150~190，体重范围是50~60，有三个样本：a(180,50)，b(190,50)，c(180,60)。那么a与b之间的闵氏距离（无论是曼哈顿距离、欧氏距离或切比雪夫距离）等于a与c之间的闵氏距离，但是身高的10cm真的等价于体重的10kg么？因此用闵氏距离来衡量这些样本间的相似度很有问题。

简单说来，闵氏距离的缺点主要有两个：

* 将各个分量的量纲(scale)，也就是“单位”当作相同的看待了。
* 没有考虑各个分量的分布（期望，方差等)可能是不同的。

### 标准化欧氏距离 ###
标准化欧氏距离是针对简单欧氏距离的缺点而作的一种改进方案。标准欧氏距离的思路：既然数据各维分量的分布不一样，好吧！那我先将各个分量都“标准化”到均值、方差相等吧。均值和方差标准化到多少呢？这里先复习点统计学知识吧，假设样本集X的均值(mean)为m，标准差(standarddeviation)为s，那么X的“标准化变量”表示为：<br>
而且标准化变量的数学期望为0，方差为1。因此样本集的标准化过程(standardization)用公式描述就是：
$$ X^{*} = \frac{X-m}{s} $$

标准化后的值 =  ( 标准化前的值  － 分量的均值 ) /分量的标准差

标准化欧氏距离的公式：
$$ d_{ij}=\sqrt{\sum_{k=1}^{n}(\frac{x_{ik}-x_{jk}}{s_{k}})^{2}} $$  

如果将方差的倒数看成是一个权重，这个公式可以看成是一种加权欧氏距离(WeightedEuclidean distance)。


### 马氏距离 ###
它是一种有效的计算两个未知样本集的相似度的方法。与欧氏距离不同的是它考虑到各种特性之间的联系,是一种采样协方差来计算两点之间距离的方法。(欧氏距离是马氏距离的特殊情形)

对于一个均值为 $ \mu=(\mu_1,\mu_2,\mu_3,\dots,\mu_p)^T $协方差矩阵为$ \sum $的多变量向量 $ x=(x_1,x_2,x_3,\dots,x_p)^T $,<br>
其马氏距离为

$$ D_M(x)=\sqrt{(x-\mu)^T\Sigma^{-1}(x-\mu)} $$

马氏距离也可以定义为两个服从同一分布并且其协方差矩阵为Σ的随机变量 $\vec{x}$与 $\vec{y}$ 的差异程度:

$$ d(\vec{x},\vec{y})=\sqrt{(\vec{x}-\vec{y})^T\Sigma^{-1} (\vec{x}-\vec{y})} $$

如果协方差矩阵为单位矩阵,那么马氏距离就简化为欧式距离,如果协方差矩阵为对角阵,则其也可称为正规化的欧氏距离'。

$$ d(\vec{x},\vec{y})= \sqrt{\sum_{i=1}^p {(x_i - y_i)^2 \over \sigma_i^2}} $$

其中 $ \sigma_i $ 是 $ x_i $ 的标准差。

* 两点之间的马氏距离与原始数据的测量单位无关。
* 标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。
* 可以排除变量之间的相关性的干扰。
* 满足距离的四个基本公理：非负性、自反性、对称性和三角不等式。