Title: webRtc 录音
Date: 2015-04-30 20:42
Modified: 2015-04-30 20:42
Category: 音视频
Tags: webRtc,C++,audio
Slug: webRtc_2015_04_30_20_42
Authors: kai_kai03
Summary: 由于不提供录音功能，so....

## 前言 ##

	Updates:
	        Status: WontFix
	        Owner:
	
	Comment #1 on issue 1567 by : How to record mixed(speaker+mic) signal to file
	
	
	True. We abandoned that functionality in WebRTC. Also File is not our focusing any more. Sorry about that.

翻google的webRtc源码，里面种种迹象表明里面有录音功能，但怎么找到没找到对应方法，然后在网上翻到了开发组给某人的回复。。。啊艹！

现在没有就算了，以后居然也不会支持！。。

不过采集和混音部分本身也是开源的，也不难办。

刚才看到别人有实现，搬过来记录一份。

## 码 ##

1、首先在VoEFile中增加一对public方法，用来开始及结束录音

	    //for Record speaker+mic
	    // Starts recording the mixed playout audio and mic.
	    virtual int StartRecordingPlayoutAndMic(const char* fileNameUTF8,
	                                      CodecInst* compression = NULL,
	                                      int maxSizeBytes = -1) = 0;
	    // Stops recording the mixed playout audio and mic.
	    virtual int StopRecordingPlayoutAndMic() = 0;

2、在SharedData类中增加一个成员变量

	    OutputMixer* _outputAllMixerPtr;    //for Record speaker+mic

3、在SharedData的构造函数及析构函数中完成该变量创建及释放

	SharedData::SharedData() :
	...
	{
	    ...
	    //for Record speaker+mic
	    if (OutputMixer::Create(_outputAllMixerPtr, _gInstanceCounter) == 0)
	    {
	        _outputAllMixerPtr->SetEngineInformation(_engineStatistics);
	    }
	    ...
	}
	
	SharedData::~SharedData()
	{
	    ...
	    OutputMixer::Destroy(_outputAllMixerPtr);//for Record speaker+mic
	    ...
	}
	
4、在实现类VoEFileImpl中实现StartRecordingPlayoutAndMic 及StopRecordingPlayoutAndMic

	//for Record speaker+mic
	int VoEFileImpl::StartRecordingPlayoutAndMic(
	    const char* fileNameUTF8, CodecInst* compression,
	    int maxSizeBytes)
	{
	    WEBRTC_TRACE(kTraceApiCall, kTraceVoice, VoEId(_instanceId,-1),
	                 "StartRecordingPlayoutAndMic(fileNameUTF8=%s, "
	                 "compression, maxSizeBytes=%d)",
	                 fileNameUTF8, maxSizeBytes);
	    assert(1024 == FileWrapper::kMaxFileNameSize);
	
	    if (!_engineStatistics.Initialized())
	    {
	        _engineStatistics.SetLastError(VE_NOT_INITED, kTraceError);
	        return -1;
	    }
	    _outputAllMixerPtr->StartRecordingPlayout(fileNameUTF8, compression);
	    return 0;
	}
	
	int VoEFileImpl::StopRecordingPlayoutAndMic()
	{
	    WEBRTC_TRACE(kTraceApiCall, kTraceVoice, VoEId(_instanceId,-1),
	                 "StopRecordingPlayoutAndMic");
	    if (!_engineStatistics.Initialized())
	    {
	        _engineStatistics.SetLastError(VE_NOT_INITED, kTraceError);
	        return -1;
	    }
	    return _outputAllMixerPtr->StopRecordingPlayout();
	}
	
5、在VoEBaseImpl中增加两个私有成员

	//for Record speaker+mic
	private:
	    AudioFrameMixerPart _afmTransmitMixer;
	    AudioFrameMixerPart _afmOutputMixer;
	
6、增加一个MixerParticipant的实现，用于拦截原有两个混淆器的输出，并合并至我们最终的录音混淆器中

	//for Record speaker+mic
	//record mic or playout signal from OutputMixer output
	class AudioFrameMixerPart:public MixerParticipant
	{
	public:
	    AudioFrameMixerPart(){};
	    void SetAudioFrame(AudioFrame &audioFrame)
	    {
	        _audioFrame = audioFrame;
	    }
	    WebRtc_UWord16 GetPayloadDataLengthInSamples()
	    {
	        return _audioFrame._payloadDataLengthInSamples;
	    }
	
	public:
	    // From MixerParticipant
	    WebRtc_Word32 GetAudioFrame(const WebRtc_Word32 id,
	                                AudioFrame& audioFrame)
	    {
	        if (_audioFrame._payloadDataLengthInSamples <= 0) return -1;
	
	        audioFrame = _audioFrame;
	        return 0;
	    };
	    WebRtc_Word32 NeededFrequency(const WebRtc_Word32 id)
	    {
	        return _audioFrame._frequencyInHz;
	    };
	
	private:
	    AudioFrame _audioFrame;
	};
	
7、在VoEBaseImpl::Init中对_outputAllMixerPtr进行初始化

	//for Record speaker+mic
	_outputAllMixerPtr->SetAudioProcessingModule(_audioProcessingModulePtr);
	_outputAllMixerPtr->SetMixabilityStatus(_afmTransmitMixer, true);
	_outputAllMixerPtr->SetMixabilityStatus(_afmOutputMixer, true);
	
8、修改VoEBaseImpl::RecordedDataIsAvailable，增加麦克风语音数据的拦截功能

	//for Record speaker+mic
	_afmTransmitMixer.SetAudioFrame(*(_transmitMixerPtr->GetAudioFrame()));
	
9、修改VoEBaseImpl::NeedMorePlayData，增加播放语音数据的拦截功能
	
	//for Record speaker+mic
	_afmOutputMixer.SetAudioFrame(*_outputMixerPtr->GetAudioFrame());
	
	...
		
	//for Record speaker+mic    
	if (_afmOutputMixer.GetPayloadDataLengthInSamples() == _afmTransmitMixer.GetPayloadDataLengthInSamples())
	{
	AudioFrame audioFrameX;
	_outputAllMixerPtr->MixActiveChannels();
	_outputAllMixerPtr->DoOperationsOnCombinedSignal();
	_outputAllMixerPtr->GetMixedAudio(samplesPerSec, nChannels, audioFrameX);
	}
	
10、因为拦截混淆语音帻时，使用了两个混淆器的内部数据，所以对TransmitMixer及OutputMixer作出修改，增加一个public方法

	public:  //for Record speaker+mic
		AudioFrame* GetAudioFrame(){return &_audioFrame;}    