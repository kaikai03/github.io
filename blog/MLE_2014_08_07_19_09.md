Title: 极大似然估计
Date: 2014-08-07 19:09
Modified: 2014-08-07 19:09
Category: MachineLearning
Tags: algorithm,Math
Slug: MLE_2014_08_07_19_09
Authors: kai_kai03
Summary: 读书笔记--最大可能性！

## Maximum Likelihood Estimate ##

### 似然函数 ###

在数理统计学中，似然函数是一种关于统计模型中的参数的函数，表示模型参数中的似然性。

似然函数在统计推断中有重大作用，如在最大似然估计和费雪信息之中的应用等等。“似然性”与“或然性”或“概率”意思相近，都是指某种事件发生的可能性，但是在统计学中，“似然性”和“或然性”或“概率”又有明确的区分。

概率 用于在已知一些参数的情况下，预测接下来的观测所得到的结果，而

似然性 则是用于在已知某些观测所得到的结果时，对有关事物的性质的参数进行估计。

在这种意义上，似然函数可以理解为条件概率的逆反。

在已知某个参数**B**时，事件**A**会发生的概率写作 $ \mathbb{P}(A \mid B) $。

$$ P(A \mid B) = \frac{P(A , B)}{P(B)} $$

利用贝叶斯定理，

$$ P(B \mid A) = \frac{P(A \mid B)\;P(B)}{P(A)} $$

因此，我们可以反过来构造表示似然性的方法：已知有事件**A**发生，运用似然函数$$ \mathbb{L}(B \mid A) $$，我们估计参数**B**的可能性。

形式上，似然函数也是一种条件概率函数，但我们关注的变量改变了：

$$ b\mapsto P(A \mid B=b) $$

注意到这里并不要求似然函数满足归一性：

$$ \sum_{b \in \mathcal{B}}{P(A \mid B=b)} = 1  $$

一个似然函数乘以一个正的常数之后仍然是似然函数。对所有$ \alpha > 0 $，都可以有似然函数：

$$ L(b \mid A) = \alpha \; P(A \mid B=b) $$

例子：

考虑投掷一枚硬币的实验。通常来说，已知投出的硬币正面朝上和反面朝上的概率各自是$ p_H = 0.5 $，便可以知道投掷若干次后出现各种结果的可能性。比如说，投两次都是正面朝上的概率是0.25。用条件概率表示，就是：

$$ P(\mbox{HH} \mid p_H = 0.5) = 0.5^2 = 0.25 $$

其中**H**表示正面朝上。

在统计学中，我们关心的是在已知一系列投掷的结果时，关于硬币投掷时正面朝上的可能性的信息。我们可以建立一个统计模型：假设硬币投出时会有$ p_H $ 的概率正面朝上，而有$ 1 − p_H $的概率反面朝上。这时，条件概率可以改写成似然函数：

$$ L(p_H = 0.5 \mid \mbox{HH}) = P(\mbox{HH}\mid p_H = 0.5) =0.25 $$

也就是说，对于取定的似然函数，在观测到两次投掷都是正面朝上时，$ p_H = 0.5 $ 的似然性是0.25（这并不表示当观测到两次正面朝上时$ p_H = 0.5 $ 的**概率**是0.25）。

如果考虑$ p_H = 0.6 $，那么似然函数的值也会改变。

$$ L(p_H = 0.6 \mid \mbox{HH}) = P(\mbox{HH}\mid p_H = 0.6) =0.36 $$

注意到似然函数的值变大了。这说明，如果参数$ p_H $的取值变成0.6的话，结果观测到连续两次正面朝上的概率要比假设$ p_H = 0.5 $时更大。也就是说，参数 $ p_H $ 取成0.6 要比取成0.5 更有说服力，更为“合理”。总之，似然函数的重要性不是它的具体取值，而是当参数变化时函数到底变小还是变大。对同一个似然函数，如果存在一个参数值，使得它的函数值达到最大的话，那么这个值就是最为“合理”的参数值。

在这个例子中，似然函数实际上等于：
$$ L(p_H = \theta \mid \mbox{HH}) = P(\mbox{HH}\mid p_H = \theta) =\theta^2 $$ 
其中 $0 \le p_H \le 1 $。

如果取$ p_H = 1 $ ，那么似然函数达到最大值1。也就是说，当连续观测到两次正面朝上时，假设硬币投掷时正面朝上的概率为1是最合理的。

类似地，如果观测到的是三次投掷硬币，头两次正面朝上，第三次反面朝上，那么似然函数将会是：
$$L(p_H = \theta \mid \mbox{HHT}) = P(\mbox{HHT}\mid p_H = \theta) =\theta^2(1 - \theta)$$ ，
其中T表示反面朝上，$ 0 \le p_H \le 1 $ 。

这时候，似然函数的最大值将会在$ p_H = \frac{2}{3} $的时候取到。也就是说，当观测到三次投掷中前两次正面朝上而后一次反面朝上时，估计硬币投掷时正面朝上的概率$ p_H = \frac{2}{3} $ 是最合理的。

### 似然估计 ###
$$ L(\theta)=L(x_1,x_2,\cdot \cdot \cdot ,x_n;\theta) = \prod_{i=1}^{n}P(x_i;\theta),\theta\in \Theta $$

既概率密度参数是 $ \theta $ 时，得到x组样本的概率。<br>
x是已知的，只有 $ \theta $ 是未知的。<br>
它是$ \theta $的函数，表示不同$ \theta $下取得当前样本的可能性。称为参数$ \theta $相对于样本集x的似然函数。

### 最大似然估计 ###
$$ \theta = argmax L(\theta) $$

有时候$ L(\theta) $ 是连乘的，还可以定义对数似然，将其变为连加：

$$ H(\theta) = \ln L(\theta) = ln\prod_{i=1}^{n}P(x_i;\theta) = \sum_{i=1}^{n}\ln P(x_i;\theta) $$

以上，要求 $ \theta $ ，只要使 $ \theta $ 的似然函数 $ L(\theta) $极大化，然后极大值对应的$ \theta $就是我们的估计。

最值等于求导，导数为0，那么方程解就是$ \theta $了。<br>
如果$ \theta $包括多个参数向量，那么求的是$ L(\theta) $对应所有参数的偏导，也就是梯度。

n个未知数就是n个方程，方程组的解就是极值点，当然也就得到几个参数。

总结：

1. 写出似然函数。
2. 对似然函数取对数，整理。
3. 求导数，令导数得0，得到似然方程。
4. 求解。